{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad865c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a2ac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run iteration_0_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8567f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run iteration_0_parameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbd8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from iteration_0_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import iteration_0_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a411afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                          Type        Data/Info\n",
      "-------------------------------------------------------\n",
      "HEALTHY                           str         H\n",
      "IMG_IN_COLOR                      int         1\n",
      "IMG_SIZE                          int         64\n",
      "Image                             module      <module 'PIL.Image' from <...>packages\\\\PIL\\\\Image.py'>\n",
      "NBR_SAMPLE                        int         20000\n",
      "PATH_DATA                         str         ../data\n",
      "PATH_DATA_EDA                     str         ../data/eda\n",
      "PATH_DATA_LIST                    str         ../data/list\n",
      "PATH_DATA_SAMPLE                  str         ../data/sample\n",
      "PATH_MODEL                        str         ../model\n",
      "PATH_ROOT                         str         ..\n",
      "PATH_SOURCE_IMG                   str         ../cell_images\n",
      "RandomForestClassifier            ABCMeta     <class 'sklearn.ensemble.<...>.RandomForestClassifier'>\n",
      "SICK                              str         S\n",
      "classification_report             function    <function classification_<...>rt at 0x000002A9AB99DF70>\n",
      "confusion_matrix                  function    <function confusion_matrix at 0x000002A9AB99D040>\n",
      "cv2                               module      <module 'cv2' from 'C:\\\\U<...>kages\\\\cv2\\\\__init__.py'>\n",
      "datetime                          type        <class 'datetime.datetime'>\n",
      "f1_score                          function    <function f1_score at 0x000002A9AB99D700>\n",
      "gc                                module      <module 'gc' (built-in)>\n",
      "glob                              module      <module 'glob' from 'C:\\\\<...>anaconda3\\\\lib\\\\glob.py'>\n",
      "gzip                              module      <module 'gzip' from 'C:\\\\<...>anaconda3\\\\lib\\\\gzip.py'>\n",
      "import_ipynb                      module      <module 'import_ipynb' fr<...>ckages\\\\import_ipynb.py'>\n",
      "learning_curve                    function    <function learning_curve at 0x000002A9ABB730D0>\n",
      "mlflow                            module      <module 'mlflow' from 'C:<...>es\\\\mlflow\\\\__init__.py'>\n",
      "np                                module      <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "os                                module      <module 'os' from 'C:\\\\Us<...>\\\\anaconda3\\\\lib\\\\os.py'>\n",
      "pd                                module      <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "pickle                            module      <module 'pickle' from 'C:<...>aconda3\\\\lib\\\\pickle.py'>\n",
      "plt                               module      <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "precision_recall_fscore_support   function    <function precision_recal<...>rt at 0x000002A9AB99DAF0>\n",
      "random                            module      <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "sns                               module      <module 'seaborn' from 'C<...>s\\\\seaborn\\\\__init__.py'>\n",
      "sp                                module      <module 'scipy.sparse' fr<...>py\\\\sparse\\\\__init__.py'>\n",
      "tqdm                              type        <class 'tqdm.std.tqdm'>\n",
      "train_test_split                  function    <function train_test_split at 0x000002A9ABB6B160>\n",
      "utils                             module      <module 'iteration_0_util<...> at 0x000002A9AF0ABC40>)>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa02d1",
   "metadata": {},
   "source": [
    "# make X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98fd2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_TIME = \"2021-11-18_20-39-00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd663ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list \n",
    "list_path_sample_img = []\n",
    "list_path_sample_img.extend(glob.glob(PATH_DATA_SAMPLE+\"/\"+DATE_TIME+ \"/\"+ \"*.pklz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b92d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with two columns: \n",
    "## path_sample_img: image path in sample\n",
    "## label: Healthy ou Sick\n",
    "def make_dataFrame(list_path_sample_img: list) -> pd.DataFrame:\n",
    "\n",
    "    df_sample_img = pd.DataFrame(columns = [\"path_sample_img\", \"label\"])\n",
    "    for path_img in tqdm(list_path_sample_img):\n",
    "\n",
    "        _, file_name, _ = utils.split_file_info(path_img)\n",
    "        label = file_name[0]\n",
    "        df_temporary = pd.DataFrame({\"path_sample_img\": path_img,\n",
    "                                     \"label\": label}, index = [0])\n",
    "        df_sample_img = pd.concat([df_sample_img, df_temporary])\n",
    "\n",
    "    # randomise and reset index\n",
    "    df_sample_img = df_sample_img.sample(frac=1).reset_index(drop = True)\n",
    "    return df_sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f131a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set options \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# to rest options\n",
    "# pd.reset_option('^display.', silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adffddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:28<00:00, 694.76it/s]\n"
     ]
    }
   ],
   "source": [
    "df_sample_img = make_dataFrame(list_path_sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e18a97f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_sample_img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>../data/sample/2021-11-18_20-39-00\\S_C182P143NThinF_IMG_20151201_172257_cell_193.pklz</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>../data/sample/2021-11-18_20-39-00\\S_C180P141NThinF_IMG_20151201_165528_cell_185.pklz</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>../data/sample/2021-11-18_20-39-00\\S_C88P49ThinF_IMG_20150820_153042_cell_212.pklz</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>../data/sample/2021-11-18_20-39-00\\S_C126P87ThinF_IMG_20151004_105100_cell_127.pklz</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16877</th>\n",
       "      <td>../data/sample/2021-11-18_20-39-00\\S_C97P58ThinF_IMG_20150917_152032_cell_180.pklz</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             path_sample_img  \\\n",
       "10320  ../data/sample/2021-11-18_20-39-00\\S_C182P143NThinF_IMG_20151201_172257_cell_193.pklz   \n",
       "6379   ../data/sample/2021-11-18_20-39-00\\S_C180P141NThinF_IMG_20151201_165528_cell_185.pklz   \n",
       "740       ../data/sample/2021-11-18_20-39-00\\S_C88P49ThinF_IMG_20150820_153042_cell_212.pklz   \n",
       "13095    ../data/sample/2021-11-18_20-39-00\\S_C126P87ThinF_IMG_20151004_105100_cell_127.pklz   \n",
       "16877     ../data/sample/2021-11-18_20-39-00\\S_C97P58ThinF_IMG_20150917_152032_cell_180.pklz   \n",
       "\n",
       "      label  \n",
       "10320     S  \n",
       "6379      S  \n",
       "740       S  \n",
       "13095     S  \n",
       "16877     S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_img.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d31b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, validation, test set\n",
    "df_path_sample_img_train, df_path_sample_img_test  = train_test_split(df_sample_img, test_size=0.2, random_state=1, \\\n",
    "                                                                          stratify=df_sample_img.label)\n",
    "\n",
    "df_path_sample_img_train, df_path_sample_img_valid = train_test_split(df_path_sample_img_train, test_size=0.2, \\\n",
    "                                                                      random_state=1, stratify=df_path_sample_img_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cdf411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split train, validation, test set\n",
    "# list_path_sample_img_train, list_path_sample_img_test  = train_test_split(list_path_sample_img, test_size=0.2)\n",
    "# list_path_sample_img_train, list_path_sample_img_valid = train_test_split(list_path_sample_img_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d9609f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Xy(list_path_sample_img: list) -> (np.array, np.array):\n",
    "    X = np.ndarray( (len(list_path_sample_img), IMG_SIZE, IMG_SIZE, 3) ,dtype = \"float16\")\n",
    "    y = np.array([\"\"] * len(list_path_sample_img))\n",
    "    for i, path in tqdm(enumerate(list_path_sample_img)):\n",
    "        \n",
    "        X[i] = utils.pickle_read(path).astype(\"float16\")\n",
    "    \n",
    "        _, file_name, _ = utils.split_file_info(path)\n",
    "        y[i] = file_name[0]\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a72ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12800it [00:11, 1075.62it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train  = make_Xy(df_path_sample_img_train.path_sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64f68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [00:02, 1079.51it/s]\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid  = make_Xy(df_path_sample_img_valid.path_sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "302ca734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [00:03, 1068.14it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test  = make_Xy(df_path_sample_img_test.path_sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb1d2a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['H', 'S'], dtype='<U1'), array([6400, 6400], dtype=int64))\n",
      "(array(['H', 'S'], dtype='<U1'), array([1600, 1600], dtype=int64))\n",
      "(array(['H', 'S'], dtype='<U1'), array([2000, 2000], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# verification\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_valid, return_counts=True))\n",
    "print(np.unique(y_test,  return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beeda530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800, 64, 64, 3)\n",
      "(3200, 64, 64, 3)\n",
      "(4000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92fdbe",
   "metadata": {},
   "source": [
    "# model_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632aae0e",
   "metadata": {},
   "source": [
    "* Ref: https://towardsdatascience.com/detecting-malaria-with-deep-learning-9e45c1e34b60\n",
    "* https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54860013",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "#percentage = 0.10\n",
    "#BATCH_SIZE = int(len(X_train) * percentage)\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 25\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19b6ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder y\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d776d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b79033",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec7bc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_enc = le.transform(y_valid)\n",
    "y_test_enc  = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "112be444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H', 'S'], dtype='<U1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b34eb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8c2d4",
   "metadata": {},
   "source": [
    "Créer un fichier .reg avec les instructions suivantes :\n",
    "\n",
    "===\n",
    "\n",
    "Windows Registry Editor Version 5.00\n",
    "\n",
    "[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem]\n",
    "\"LongPathsEnabled\"=dword:00000001\n",
    "\n",
    "---\n",
    "\n",
    "Exécuter le .reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "646e9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62add767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fc97c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8798a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c7f239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.grid()\n",
    "    plt.title('binary_crossentropy')\n",
    "    plt.plot(history.history['loss'], \"o-\", color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], \"o-\", color='orange', label='validation')\n",
    "    plt.legend()    \n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.grid()\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], \"o-\",color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], \"o-\",color='orange', label='validation')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13778f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_5 = Sequential()\n",
    "model_cnn_5.add(tf.keras.layers.Input(name = \"input\", shape=INPUT_SHAPE))\n",
    "model_cnn_5.add(tf.keras.layers.Conv2D(name = \"conv2D\",\n",
    "                                     filters=32,\n",
    "                                     kernel_size=(3,3),\n",
    "                                     activation=\"LeakyReLU\",\n",
    "                                     padding=\"same\",\n",
    "                                     kernel_initializer=\"he_uniform\"\n",
    "                                    ))\n",
    "model_cnn_5.add(tf.keras.layers.MaxPooling2D(name=\"pooling\", pool_size=(2,2)))\n",
    "\n",
    "model_cnn_5.add(tf.keras.layers.Conv2D(name = \"conv2D_2\",\n",
    "                                     filters=64,\n",
    "                                     kernel_size=(3,3),\n",
    "                                     activation=\"LeakyReLU\",\n",
    "                                     padding=\"same\",\n",
    "                                     kernel_initializer=\"he_uniform\"\n",
    "                                    ))\n",
    "model_cnn_5.add(tf.keras.layers.MaxPooling2D(name=\"pooling_2\", pool_size=(2,2)))\n",
    "\n",
    "model_cnn_5.add(tf.keras.layers.Conv2D(name = \"conv2D_3\",\n",
    "                                     filters=128,\n",
    "                                     kernel_size=(3,3),\n",
    "                                     activation=\"LeakyReLU\",\n",
    "                                     padding=\"same\",\n",
    "                                     kernel_initializer=\"he_uniform\"\n",
    "                                    ))\n",
    "model_cnn_5.add(tf.keras.layers.MaxPooling2D(name=\"pooling_3\", pool_size=(2,2)))\n",
    "\n",
    "model_cnn_5.add(tf.keras.layers.Flatten(name=\"flatten\"))\n",
    "model_cnn_5.add(tf.keras.layers.Dense(name=\"dense_hidden\", units = 1024, activation=\"LeakyReLU\",\n",
    "                                    kernel_initializer=\"he_uniform\" ))\n",
    "model_cnn_5.add(tf.keras.layers.Dense(name=\"dense_hidden_2\", units = 128, activation=\"LeakyReLU\",\n",
    "                                    kernel_initializer=\"he_uniform\" ))\n",
    "model_cnn_5.add(tf.keras.layers.Dense(name=\"ouput\", units = 1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29ac772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiler modele\n",
    "model_cnn_5.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\\\n",
    "                    loss =\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d4567cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2D (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "pooling (MaxPooling2D)       (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2D_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "pooling_2 (MaxPooling2D)     (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2D_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "pooling_3 (MaxPooling2D)     (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_hidden (Dense)         (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dense_hidden_2 (Dense)       (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "ouput (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,614,209\n",
      "Trainable params: 8,614,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "798ad53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b4bfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=359, \\\n",
    "                         zoom_range=0.15, \\\n",
    "                         width_shift_range=0.2, height_shift_range=0.2, \\\n",
    "                         shear_range=0.15, \\\n",
    "                         horizontal_flip=True, \\\n",
    "                         vertical_flip=True, \\\n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0157bda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4df37c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b0e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25/25 [==============================] - 93s 4s/step - loss: 2.1359 - accuracy: 0.5387 - val_loss: 0.6626 - val_accuracy: 0.6200\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 99s 4s/step - loss: 0.6489 - accuracy: 0.6240 - val_loss: 0.6338 - val_accuracy: 0.6719\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 98s 4s/step - loss: 0.6343 - accuracy: 0.6460 - val_loss: 0.6436 - val_accuracy: 0.6294\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 94s 4s/step - loss: 0.6204 - accuracy: 0.6622 - val_loss: 0.6036 - val_accuracy: 0.6822\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.6248 - accuracy: 0.6576 - val_loss: 0.6001 - val_accuracy: 0.6794\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 95s 4s/step - loss: 0.6387 - accuracy: 0.6433 - val_loss: 0.6342 - val_accuracy: 0.6612\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.6110 - accuracy: 0.6685 - val_loss: 0.5776 - val_accuracy: 0.7063\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.5858 - accuracy: 0.6964 - val_loss: 0.5530 - val_accuracy: 0.7216\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.5817 - accuracy: 0.6967 - val_loss: 0.5757 - val_accuracy: 0.7088\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 91s 4s/step - loss: 0.5583 - accuracy: 0.7141 - val_loss: 0.5290 - val_accuracy: 0.7250\n",
      "Epoch 11/25\n",
      "17/25 [===================>..........] - ETA: 27s - loss: 0.5392 - accuracy: 0.7306"
     ]
    }
   ],
   "source": [
    "history_5 = model_cnn_5.fit( \\\n",
    "                            aug.flow(X_train, y_train_enc, batch_size=BATCH_SIZE, subset=None), \\\n",
    "                            validation_data = (X_valid, y_valid_enc), \\\n",
    "                            steps_per_epoch = len(X_train) // BATCH_SIZE, \\\n",
    "                            epochs = EPOCHS\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4581a52",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a420c",
   "metadata": {},
   "source": [
    "* Mettre des dropOut\n",
    "* faire équivalent de predict_classes() qui n'existe plus dans tf nouvelle version.:\n",
    "    * On pourra utiliser la proba retournée par model.predict, if >0.50 classe 1\n",
    "* evaluer avec X_test et matrice de confusion\n",
    "* reprendre les lignes de suivi des metriques avec MLFlow comme on a fait pour RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_cnn_5.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # matrice de confusion\n",
    "# from sklearn import metrics\n",
    "# metrics.confusion_matrix(y_test_enc, y_pred, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db086916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65267787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmenter Batch Size = int(len(X_Tain) * %) + 1\n",
    "#Reduire le learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6956d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cnn_4.save(PATH_MODEL + \"/model_cnn_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a41c7",
   "metadata": {},
   "source": [
    "Keras avec GPU AMD\n",
    "https://medium.com/@Vatsal410/keras-without-nvidia-gpus-with-plaidml-and-amd-gpu-4ba6f60025ce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
